{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "import torch.distributed as dist\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import test  # import test.py to get mAP after each epoch\n",
        "from models import *\n",
        "from utils.datasets import *\n",
        "from utils.utils import *\n",
        "\n",
        "#from azureml.core import Run\n",
        "\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1612228497450
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mixed_precision = False\n",
        "\n",
        "#wdir = 'weights' + os.sep  # weights dir\n",
        "#last = wdir + 'last.pt'\n",
        "#best = wdir + 'best.pt'\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "\n",
        "wdir = 'outputs' + os.sep\n",
        "last = wdir + 'last.pt'\n",
        "best = wdir + 'best.pt'\n",
        "results_file = 'results.txt'\n",
        "\n",
        "# Hyperparameters\n",
        "hyp = {'giou': 3.54,  # giou loss gain\n",
        "       'cls': 37.4,  # cls loss gain\n",
        "       'cls_pw': 1.0,  # cls BCELoss positive_weight\n",
        "       'obj': 64.3,  # obj loss gain (*=img_size/320 if img_size != 320)\n",
        "       'obj_pw': 1.0,  # obj BCELoss positive_weight\n",
        "       'iou_t': 0.20,  # iou training threshold\n",
        "       'lr0': 0.01,  # initial learning rate (SGD=5E-3, Adam=5E-4)\n",
        "       'lrf': 0.0005,  # final learning rate (with cos scheduler)\n",
        "       'momentum': 0.937,  # SGD momentum\n",
        "       'weight_decay': 0.000484,  # optimizer weight decay\n",
        "       'fl_gamma': 0.0,  # focal loss gamma (efficientDet default is gamma=1.5)\n",
        "       'hsv_h': 0.0138,  # image HSV-Hue augmentation (fraction)\n",
        "       'hsv_s': 0.678,  # image HSV-Saturation augmentation (fraction)\n",
        "       'hsv_v': 0.36,  # image HSV-Value augmentation (fraction)\n",
        "       'degrees': 1.98 * 0,  # image rotation (+/- deg)\n",
        "       'translate': 0.05 * 0,  # image translation (+/- fraction)\n",
        "       'scale': 0.05 * 0,  # image scale (+/- gain)\n",
        "       'shear': 0.641 * 0}  # image shear (+/- deg)\n",
        "\n",
        "# Overwrite hyp with hyp*.txt (optional)\n",
        "f = glob.glob('hyp*.txt')\n",
        "if f:\n",
        "    print('Using %s' % f[0])\n",
        "    for k, v in zip(hyp.keys(), np.loadtxt(f[0])):\n",
        "        hyp[k] = v\n",
        "\n",
        "# Print focal loss if gamma > 0\n",
        "if hyp['fl_gamma']:\n",
        "    print('Using FocalLoss(gamma=%g)' % hyp['fl_gamma'])"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1612228519769
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#parser = argparse.ArgumentParser()\n",
        "#parser.add_argument('--epochs', type=int, default=5)  # 500200 batches at bs 16, 117263 COCO images = 273 epochs\n",
        "epochs = 5\n",
        "#parser.add_argument('--batch-size', type=int, default=6)  # effective bs = batch_size * accumulate = 16 * 4 = 64\n",
        "batch_size = 6\n",
        "#parser.add_argument('--cfg', type=str, default='cfg/yolov3-tiny-3cls.cfg', help='*.cfg path')\n",
        "cfg = 'cfg/yolov3-tiny-3cls.cfg'\n",
        "#parser.add_argument('--data', type=str, default='data/anji_detect-test.data', help='*.data path')\n",
        "data = 'data/anji_detect-test.data'\n",
        "#parser.add_argument('--multi-scale', action='store_true', help='adjust (67%% - 150%%) img_size every 10 batches')\n",
        "multi_scale = False\n",
        "#parser.add_argument('--img-size', nargs='+', type=int, default=[320, 640], help='[min_train, max-train, test]')\n",
        "img_size = [320,640]\n",
        "#parser.add_argument('--rect', action='store_true', help='rectangular training')\n",
        "#parser.add_argument('--resume', action='store_true', help='resume training from last.pt')\n",
        "#parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')\n",
        "#parser.add_argument('--notest', action='store_true', help='only test final epoch')\n",
        "#parser.add_argument('--evolve', action='store_true', help='evolve hyperparameters')\n",
        "rect = False\n",
        "resume = False\n",
        "nosave = False\n",
        "notest = False\n",
        "evolve = False\n",
        "#parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')\n",
        "bucket = ''\n",
        "#parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')\n",
        "cache_images = False\n",
        "#parser.add_argument('--weights', type=str, default='weights/yolov3-tiny.conv.15', help='initial weights path')\n",
        "weights = 'weights/yolov3-tiny.conv.15'\n",
        "#parser.add_argument('--name', default='', help='renames results.txt to results_name.txt if supplied')\n",
        "name = ''\n",
        "#parser.add_argument('--device', default='', help='device id (i.e. 0 or 0,1 or cpu)')\n",
        "device = ''\n",
        "#parser.add_argument('--adam', action='store_true', help='use adam optimizer')\n",
        "adam = False\n",
        "#parser.add_argument('--single-cls', action='store_true', help='train as single-class dataset')\n",
        "single_cls = False\n",
        "#parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
        "#opt = parser.parse_args()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1612228525037
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#weights = last if resume else weights\n",
        "#    check_git_status()\n",
        "img_size.extend([img_size[-1]] * (3 - len(img_size))) "
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1612228531230
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch_utils.select_device(device, apex=mixed_precision, batch_size=batch_size)\n",
        "print(device.type)\n",
        "if device.type == 'cpu':\n",
        "    mixed_precision = False\n",
        "print(mixed_precision)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA device0 _CudaDeviceProperties(name='Tesla K80', total_memory=11441MB)\n",
            "\n",
            "cuda\n",
            "False\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1612228542810
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accumulate = max(round(64 / batch_size), 1)  # accumulate n times before optimizer update (bs 64)\n",
        "print(accumulate)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1612228550299
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgsz_min, imgsz_max, imgsz_test = img_size \n",
        "print(imgsz_min,imgsz_max,imgsz_test)\n",
        "gs = 64  # (pixels) grid size\n",
        "assert math.fmod(imgsz_min, gs) == 0, '--img-size %g must be a %g-multiple' % (imgsz_min, gs)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320 640 640\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1612228569306
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(multi_scale)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1612228576344
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_scale |= imgsz_min != imgsz_max  # multi if different (min, max)\n",
        "print(multi_scale)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1612228580742
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if multi_scale:\n",
        "        if imgsz_min == imgsz_max:\n",
        "            imgsz_min //= 1.5\n",
        "            imgsz_max //= 0.667\n",
        "        grid_min, grid_max = imgsz_min // gs, imgsz_max // gs\n",
        "        imgsz_min, imgsz_max = int(grid_min * gs), int(grid_max * gs)\n",
        "img_size = imgsz_max  # initialize with max size"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1612228585692
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init_seeds()\n",
        "data_dict = parse_data_cfg(data)\n",
        "train_path = data_dict['train']\n",
        "test_path = data_dict['valid']\n",
        "print(train_path)\n",
        "print(test_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/train_local.txt\n",
            "data/val_local.txt\n"
          ]
        }
      ],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1612230010665
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(int(data_dict['classes']))\n",
        "print(single_cls)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "False\n"
          ]
        }
      ],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1612230015416
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nc = 1 if single_cls else int(data_dict['classes'])  # number of classes\n",
        "hyp['cls'] *= nc / 80\n",
        "print(nc)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1612230021245
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove previous results\n",
        "for f in glob.glob('*_batch*.jpg') + glob.glob(results_file):\n",
        "    os.remove(f)"
      ],
      "outputs": [],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1612230025882
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(cfg)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cfg/yolov3-tiny-3cls.cfg\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1612229418402
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = Darknet(cfg).to(device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Summary: 37 layers, 8.6745e+06 parameters, 8.6745e+06 gradients\n"
          ]
        }
      ],
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1612230031904
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "pg0, pg1, pg2 = [], [], []  # optimizer parameter groups\n",
        "for k, v in dict(model.named_parameters()).items():\n",
        "    if '.bias' in k:\n",
        "        pg2 += [v]  # biases\n",
        "    elif 'Conv2d.weight' in k:\n",
        "        pg1 += [v]  # apply weight_decay\n",
        "    else:\n",
        "        pg0 += [v]  # all else"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1612230037410
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pg2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([ 1.38910e-02,  7.43582e-03,  2.80491e-02, -9.56991e-03, -4.50293e+00, -1.16900e+00, -1.21391e+00, -1.23476e+00,  8.56011e-03,  3.32031e-02,  2.04062e-02,  3.67516e-03, -4.52799e+00, -1.23441e+00, -1.22660e+00, -1.21941e+00,  4.10424e-02, -3.71889e-02, -3.79907e-02,  3.32781e-03, -4.46921e+00, -1.19514e+00,\n",
            "        -1.24240e+00, -1.23263e+00], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\n",
            "tensor([-9.63692e-03,  4.63675e-02,  2.67509e-02,  3.54687e-02, -4.53759e+00, -1.15058e+00, -1.20986e+00, -1.18319e+00,  3.84825e-02, -1.95564e-03, -6.19167e-02,  1.45990e-02, -4.53755e+00, -1.19862e+00, -1.22860e+00, -1.16096e+00, -5.32212e-02, -6.17828e-02,  6.00369e-02,  5.09122e-02, -4.46140e+00, -1.23156e+00,\n",
            "        -1.20590e+00, -1.17639e+00], device='cuda:0', requires_grad=True)]\n"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(adam)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(pg0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)\n",
        "optimizer.add_param_group({'params': pg1, 'weight_decay': hyp['weight_decay']})  # add pg1 with weight_decay\n",
        "optimizer.add_param_group({'params': pg2})  # add pg2 (biases)\n",
        "print('Optimizer groups: %g .bias, %g Conv2d.weight, %g other' % (len(pg2), len(pg1), len(pg0)))\n",
        "del pg0, pg1, pg2"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer groups: 13 .bias, 13 Conv2d.weight, 11 other\n"
          ]
        }
      ],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1612230046661
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch = 0\n",
        "best_fitness = 0.0\n",
        "attempt_download(weights)"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1612230051333
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(weights.endswith('.pt'),len(weights)>0)\n",
        "load_darknet_weights(model, weights)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False True\n"
          ]
        }
      ],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1612230058010
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(mixed_precision)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Scheduler https://arxiv.org/pdf/1812.01187.pdf\n",
        "lf = lambda x: (((1 + math.cos(x * math.pi / epochs)) / 2) ** 1.0) * 0.95 + 0.05  # cosine\n",
        "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
        "scheduler.last_epoch = start_epoch - 1  # see link below\n",
        "# https://discuss.pytorch.org/t/a-problem-occured-when-resuming-an-optimizer/28822"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1612230064015
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(scheduler.last_epoch)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1\n"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(device.type,torch.cuda.device_count(),torch.cuda.device_count() > 1,torch.distributed.is_available())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda 1 False True\n"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(hyp,rect,cache_images,single_cls)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'giou': 3.54, 'cls': 1.4024999999999999, 'cls_pw': 1.0, 'obj': 64.3, 'obj_pw': 1.0, 'iou_t': 0.2, 'lr0': 0.01, 'lrf': 0.0005, 'momentum': 0.937, 'weight_decay': 0.000484, 'fl_gamma': 0.0, 'hsv_h': 0.0138, 'hsv_s': 0.678, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0} False False False\n"
          ]
        }
      ],
      "execution_count": 28,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = LoadImagesAndLabels(train_path, img_size, batch_size,\n",
        "                                  augment=True,\n",
        "                                  hyp=hyp,  # augmentation hyperparameters\n",
        "                                  rect=rect,  # rectangular training\n",
        "                                  cache_images=cache_images,\n",
        "                                  single_cls=single_cls)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "No images found in data/train_local.txt. See https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-260c8ebc1f55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   \u001b[0mrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# rectangular training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   \u001b[0mcache_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                   single_cls=single_cls)\n\u001b[0m",
            "\u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/dev-vm-gpu/code/Users/johchen/Projects/CV-Yolov3-Sample/utils/datasets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, img_size, batch_size, augment, hyp, rect, image_weights, cache_images, single_cls)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m#print(self.img_files)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'No images found in %s. See %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0mbi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# batch index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# number of batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: No images found in data/train_local.txt. See https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data"
          ]
        }
      ],
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1612229521134
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<utils.datasets.LoadImagesAndLabels object at 0x7f870c496c50>\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1612229540804
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "batch_size = min(batch_size, len(dataset))\n",
        "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
        "dataloader = torch.utils.data.DataLoader(dataset,\n",
        "                                             batch_size=batch_size,\n",
        "                                             num_workers=nw,\n",
        "                                             shuffle=not rect,  # Shuffle=True unless rectangular training is used\n",
        "                                             pin_memory=True,\n",
        "                                             collate_fn=dataset.collate_fn)"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1612229550921
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testloader = torch.utils.data.DataLoader(LoadImagesAndLabels(test_path, imgsz_test, batch_size,\n",
        "                                                                 hyp=hyp,\n",
        "                                                                 rect=True,\n",
        "                                                                 cache_images=cache_images,\n",
        "                                                                 single_cls=single_cls),\n",
        "                                             batch_size=batch_size,\n",
        "                                             num_workers=nw,\n",
        "                                             pin_memory=True,\n",
        "                                             collate_fn=dataset.collate_fn)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCaching labels:   0%|          | 0/2117 [00:00<?, ?it/s]\r",
            "Caching labels: 100%|██████████| 2117/2117 [00:00<00:00, 168016.61it/s]\n"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1612229557261
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "model.nc = nc  # attach number of classes to model\n",
        "model.hyp = hyp  # attach hyperparameters to model\n",
        "model.gr = 1.0  # giou loss ratio (obj_loss = 1.0 or giou)\n",
        "model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device)  # attach class weights\n",
        "\n",
        "# Model EMA\n",
        "ema = torch_utils.ModelEMA(model)\n",
        "\n",
        "# Start training\n",
        "nb = len(dataloader)  # number of batches\n",
        "n_burn = max(3 * nb, 500)  # burn-in iterations, max(3 epochs, 500 iterations)\n",
        "maps = np.zeros(nc)  # mAP per class\n",
        "# torch.autograd.set_detect_anomaly(True)\n",
        "results = (0, 0, 0, 0, 0, 0, 0)  # 'P', 'R', 'mAP', 'F1', 'val GIoU', 'val Objectness', 'val Classification'\n",
        "t0 = time.time()\n",
        "print('Image sizes %g - %g train, %g test' % (imgsz_min, imgsz_max, imgsz_test))\n",
        "print('Using %g dataloader workers' % nw)\n",
        "print('Starting training for %g epochs...' % epochs)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image sizes 320 - 640 train, 640 test\n",
            "Using 6 dataloader workers\n",
            "Starting training for 5 epochs...\n"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1612229580585
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.image_weights)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "execution_count": 71,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 0"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1612229616513
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "Darknet(\n  (module_list): ModuleList(\n    (0): Sequential(\n      (Conv2d): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (BatchNorm2d): BatchNorm2d(16, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n    )\n    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (2): Sequential(\n      (Conv2d): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n    )\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n    )\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Sequential(\n      (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n    )\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Sequential(\n      (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n    )\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Sequential(\n      (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n    )\n    (11): Sequential(\n      (ZeroPad2d): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n      (MaxPool2d): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n    )\n    (12): Sequential(\n      (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n    )\n    (13): Sequential(\n      (Conv2d): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n    )\n    (14): Sequential(\n      (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n    )\n    (15): Sequential(\n      (Conv2d): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (16): YOLOLayer()\n    (17): FeatureConcat()\n    (18): Sequential(\n      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n    )\n    (19): Upsample(scale_factor=2.0, mode=nearest)\n    (20): FeatureConcat()\n    (21): Sequential(\n      (Conv2d): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n    )\n    (22): Sequential(\n      (Conv2d): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (23): YOLOLayer()\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1612229620712
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mloss = torch.zeros(4).to(device)  # mean losses\n",
        "print(('\\n' + '%10s' * 8) % ('Epoch', 'gpu_mem', 'GIoU', 'obj', 'cls', 'total', 'targets', 'img_size'))\n",
        "pbar = tqdm(enumerate(dataloader), total=nb)  # progress bar"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1045 [00:00<?, ?it/s]"
          ]
        }
      ],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1612229630215
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(mixed_precision,start_epoch,epochs)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False 0 5\n"
          ]
        }
      ],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1612229638556
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch -------------------------------------------------------------\n",
        "for i, (imgs, targets, paths, _) in pbar:  \n",
        "    ni = i + nb * epoch  # number integrated batches (since train start)\n",
        "    imgs = imgs.to(device).float() / 255.0  # uint8 to float32, 0 - 255 to 0.0 - 1.0\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # Burn-in\n",
        "    if ni <= n_burn * 2:\n",
        "        model.gr = np.interp(ni, [0, n_burn * 2], [0.0, 1.0])  # giou loss ratio (obj_loss = 1.0 or giou)\n",
        "        if ni == n_burn:  # burnin complete\n",
        "            print_model_biases(model)\n",
        "\n",
        "        for j, x in enumerate(optimizer.param_groups):\n",
        "            # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n",
        "            x['lr'] = np.interp(ni, [0, n_burn], [0.1 if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n",
        "            if 'momentum' in x:\n",
        "                x['momentum'] = np.interp(ni, [0, n_burn], [0.9, hyp['momentum']])\n",
        "\n",
        "    # Multi-Scale\n",
        "    if multi_scale:\n",
        "        if ni / accumulate % 1 == 0:  #  adjust img_size (67% - 150%) every 1 batch\n",
        "            img_size = random.randrange(grid_min, grid_max + 1) * gs\n",
        "        sf = img_size / max(imgs.shape[2:])  # scale factor\n",
        "        if sf != 1:\n",
        "            ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to 32-multiple)\n",
        "            imgs = F.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)\n",
        "\n",
        "    # Forward\n",
        "    pred = model(imgs)\n",
        "\n",
        "    # Loss\n",
        "    loss, loss_items = compute_loss(pred, targets, model)\n",
        "    #if not torch.isfinite(loss):\n",
        "    #    print('WARNING: non-finite loss, ending training ', loss_items)\n",
        "    #    return results\n",
        "\n",
        "    # Backward\n",
        "    loss *= batch_size / 64  # scale loss\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimize\n",
        "    if ni % accumulate == 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        ema.update(model)\n",
        "\n",
        "    # Print\n",
        "    mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n",
        "    #mem = '%.3gG' % (torch.cuda.memory_cached() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n",
        "    mem = '%.3gG' % (torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n",
        "    s = ('%10s' * 2 + '%10.3g' * 6) % ('%g/%g' % (epoch, epochs - 1), mem, *mloss, len(targets), img_size)\n",
        "    pbar.set_description(s)\n",
        "\n",
        "    # Plot\n",
        "    if ni < 1:\n",
        "        f = 'train_batch%g.jpg' % i  # filename\n",
        "        res = plot_images(images=imgs, targets=targets, paths=paths, fname=f)\n",
        "        if tb_writer:\n",
        "            tb_writer.add_image(f, res, dataformats='HWC', global_step=epoch)\n",
        "            # tb_writer.add_graph(model, imgs)  # add model to tensorboard\n",
        "# end batch ------------------------------------------------------------------------------------------------"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r",
            "  0%|          | 0/1045 [00:18<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Caught AssertionError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/dev-vm-gpu/code/Users/johchen/Projects/CV-Yolov3-Sample/utils/datasets.py\", line 419, in __getitem__\n    img, labels = load_mosaic(self, index)\n  File \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/dev-vm-gpu/code/Users/johchen/Projects/CV-Yolov3-Sample/utils/datasets.py\", line 548, in load_mosaic\n    img, _, (h, w) = load_image(self, index)\n  File \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/dev-vm-gpu/code/Users/johchen/Projects/CV-Yolov3-Sample/utils/datasets.py\", line 509, in load_image\n    assert img is not None, 'Image Not Found ' + path\nAssertionError: Image Not Found https://amlpocwestus6466069240.blob.core.windows.net/source-data/anji_data/images/camera10_202007060833_camera10_Clip_76_33-09_34-09_720.jpg\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-78aee7bb88a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# batch -------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepoch\u001b[0m  \u001b[0;31m# number integrated batches (since train start)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m  \u001b[0;31m# uint8 to float32, 0 - 255 to 0.0 - 1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: Caught AssertionError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/dev-vm-gpu/code/Users/johchen/Projects/CV-Yolov3-Sample/utils/datasets.py\", line 419, in __getitem__\n    img, labels = load_mosaic(self, index)\n  File \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/dev-vm-gpu/code/Users/johchen/Projects/CV-Yolov3-Sample/utils/datasets.py\", line 548, in load_mosaic\n    img, _, (h, w) = load_image(self, index)\n  File \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/dev-vm-gpu/code/Users/johchen/Projects/CV-Yolov3-Sample/utils/datasets.py\", line 509, in load_image\n    assert img is not None, 'Image Not Found ' + path\nAssertionError: Image Not Found https://amlpocwestus6466069240.blob.core.windows.net/source-data/anji_data/images/camera10_202007060833_camera10_Clip_76_33-09_34-09_720.jpg\n"
          ]
        }
      ],
      "execution_count": 32,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Update scheduler\n",
        "scheduler.step()"
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(notest)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "execution_count": 93,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Process epoch results\n",
        "ema.update_attr(model)\n",
        "final_epoch = epoch + 1 == epochs\n",
        "print(final_epoch)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "execution_count": 53,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "if not notest or final_epoch:  # Calculate mAP\n",
        "            is_coco = any([x in data for x in ['coco.data', 'coco2014.data', 'coco2017.data']]) and model.nc == 80\n",
        "            results, maps = test.test(cfg,\n",
        "                                      data,\n",
        "                                      batch_size=batch_size,\n",
        "                                      img_size=imgsz_test,\n",
        "                                      model=ema.ema,\n",
        "                                      save_json=final_epoch and is_coco,\n",
        "                                      single_cls=single_cls,\n",
        "                                      dataloader=testloader)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 353/353 [01:04<00:00,  5.51it/s]\n",
            "                 all  2.12e+03  8.28e+03     0.346     0.543     0.401     0.417\n"
          ]
        }
      ],
      "execution_count": 54,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Write\n",
        "with open(results_file, 'a') as f:\n",
        "    f.write(s + '%10.3g' * 7 % results + '\\n')  # P, R, mAP, F1, test_losses=(GIoU, obj, cls)\n",
        "if len(name) and bucket:\n",
        "    os.system('gsutil cp results.txt gs://%s/results/results%s.txt' % (bucket, name))"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "fi = fitness(np.array(results).reshape(1, -1))  # fitness_i = weighted combination of [P, R, mAP, F1]\n",
        "if fi > best_fitness:\n",
        "    best_fitness = fi"
      ],
      "outputs": [],
      "execution_count": 55,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_fitness)\n",
        "print('the best_fitness is %f .\\n' % (best_fitness))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    0.40265]\n",
            "the best_fitness is 0.402650 .\n",
            "\n"
          ]
        }
      ],
      "execution_count": 56,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "save = (not opt.nosave) or (final_epoch and not opt.evolve)\n",
        "if save:\n",
        "    with open(results_file, 'r') as f:  # create checkpoint\n",
        "        chkpt = {'epoch': epoch,\n",
        "                         'best_fitness': best_fitness,\n",
        "                         'training_results': f.read(),\n",
        "                         'model': ema.ema.module.state_dict() if hasattr(model, 'module') else ema.ema.state_dict(),\n",
        "                         'optimizer': None if final_epoch else optimizer.state_dict()}\n",
        "\n",
        "            # Save last, best and delete\n",
        "        torch.save(chkpt, last)\n",
        "        if (best_fitness == fi) and not final_epoch:\n",
        "            torch.save(chkpt, best)\n",
        "        del chkpt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.device_count() )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "execution_count": 59,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1612229953670
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}