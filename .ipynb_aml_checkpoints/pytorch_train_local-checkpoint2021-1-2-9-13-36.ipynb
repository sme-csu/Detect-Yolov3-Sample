{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch.distributed as dist\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import test  # import test.py to get mAP after each epoch\n",
    "from models import *\n",
    "from utils.datasets import *\n",
    "from utils.utils import *\n",
    "\n",
    "#from azureml.core import Run\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision = False\n",
    "\n",
    "#wdir = 'weights' + os.sep  # weights dir\n",
    "#last = wdir + 'last.pt'\n",
    "#best = wdir + 'best.pt'\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "wdir = 'outputs' + os.sep\n",
    "last = wdir + 'last.pt'\n",
    "best = wdir + 'best.pt'\n",
    "results_file = 'results.txt'\n",
    "\n",
    "# Hyperparameters\n",
    "hyp = {'giou': 3.54,  # giou loss gain\n",
    "       'cls': 37.4,  # cls loss gain\n",
    "       'cls_pw': 1.0,  # cls BCELoss positive_weight\n",
    "       'obj': 64.3,  # obj loss gain (*=img_size/320 if img_size != 320)\n",
    "       'obj_pw': 1.0,  # obj BCELoss positive_weight\n",
    "       'iou_t': 0.20,  # iou training threshold\n",
    "       'lr0': 0.01,  # initial learning rate (SGD=5E-3, Adam=5E-4)\n",
    "       'lrf': 0.0005,  # final learning rate (with cos scheduler)\n",
    "       'momentum': 0.937,  # SGD momentum\n",
    "       'weight_decay': 0.000484,  # optimizer weight decay\n",
    "       'fl_gamma': 0.0,  # focal loss gamma (efficientDet default is gamma=1.5)\n",
    "       'hsv_h': 0.0138,  # image HSV-Hue augmentation (fraction)\n",
    "       'hsv_s': 0.678,  # image HSV-Saturation augmentation (fraction)\n",
    "       'hsv_v': 0.36,  # image HSV-Value augmentation (fraction)\n",
    "       'degrees': 1.98 * 0,  # image rotation (+/- deg)\n",
    "       'translate': 0.05 * 0,  # image translation (+/- fraction)\n",
    "       'scale': 0.05 * 0,  # image scale (+/- gain)\n",
    "       'shear': 0.641 * 0}  # image shear (+/- deg)\n",
    "\n",
    "# Overwrite hyp with hyp*.txt (optional)\n",
    "f = glob.glob('hyp*.txt')\n",
    "if f:\n",
    "    print('Using %s' % f[0])\n",
    "    for k, v in zip(hyp.keys(), np.loadtxt(f[0])):\n",
    "        hyp[k] = v\n",
    "\n",
    "# Print focal loss if gamma > 0\n",
    "if hyp['fl_gamma']:\n",
    "    print('Using FocalLoss(gamma=%g)' % hyp['fl_gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--epochs', type=int, default=5)  # 500200 batches at bs 16, 117263 COCO images = 273 epochs\n",
    "epochs = 5\n",
    "#parser.add_argument('--batch-size', type=int, default=6)  # effective bs = batch_size * accumulate = 16 * 4 = 64\n",
    "batch_size = 6\n",
    "#parser.add_argument('--cfg', type=str, default='cfg/yolov3-tiny-3cls.cfg', help='*.cfg path')\n",
    "cfg = 'cfg/yolov3-tiny-3cls.cfg'\n",
    "#parser.add_argument('--data', type=str, default='data/anji_detect-test.data', help='*.data path')\n",
    "data = 'data/anji_detect-test.data'\n",
    "#parser.add_argument('--multi-scale', action='store_true', help='adjust (67%% - 150%%) img_size every 10 batches')\n",
    "multi_scale = False\n",
    "#parser.add_argument('--img-size', nargs='+', type=int, default=[320, 640], help='[min_train, max-train, test]')\n",
    "img_size = [320,640]\n",
    "#parser.add_argument('--rect', action='store_true', help='rectangular training')\n",
    "#parser.add_argument('--resume', action='store_true', help='resume training from last.pt')\n",
    "#parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')\n",
    "#parser.add_argument('--notest', action='store_true', help='only test final epoch')\n",
    "#parser.add_argument('--evolve', action='store_true', help='evolve hyperparameters')\n",
    "rect = False\n",
    "resume = False\n",
    "nosave = False\n",
    "notest = False\n",
    "evolve = False\n",
    "#parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')\n",
    "bucket = ''\n",
    "#parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')\n",
    "cache_images = False\n",
    "#parser.add_argument('--weights', type=str, default='weights/yolov3-tiny.conv.15', help='initial weights path')\n",
    "weights = 'weights/yolov3-tiny.conv.15'\n",
    "#parser.add_argument('--name', default='', help='renames results.txt to results_name.txt if supplied')\n",
    "name = ''\n",
    "#parser.add_argument('--device', default='', help='device id (i.e. 0 or 0,1 or cpu)')\n",
    "device = ''\n",
    "#parser.add_argument('--adam', action='store_true', help='use adam optimizer')\n",
    "adam = False\n",
    "#parser.add_argument('--single-cls', action='store_true', help='train as single-class dataset')\n",
    "single_cls = False\n",
    "#parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "#opt = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = last if resume else weights\n",
    "#    check_git_status()\n",
    "img_size.extend([img_size[-1]] * (3 - len(img_size))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using CUDA device0 _CudaDeviceProperties(name='GeForce GTX 1050', total_memory=2048MB)\n\ncuda\nFalse\n"
     ]
    }
   ],
   "source": [
    "device = torch_utils.select_device(device, apex=mixed_precision, batch_size=batch_size)\n",
    "print(device.type)\n",
    "if device.type == 'cpu':\n",
    "    mixed_precision = False\n",
    "print(mixed_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "accumulate = max(round(64 / batch_size), 1)  # accumulate n times before optimizer update (bs 64)\n",
    "print(accumulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "320 640 640\n"
     ]
    }
   ],
   "source": [
    "imgsz_min, imgsz_max, imgsz_test = img_size \n",
    "print(imgsz_min,imgsz_max,imgsz_test)\n",
    "gs = 64  # (pixels) grid size\n",
    "assert math.fmod(imgsz_min, gs) == 0, '--img-size %g must be a %g-multiple' % (imgsz_min, gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(multi_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "multi_scale |= imgsz_min != imgsz_max  # multi if different (min, max)\n",
    "print(multi_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_scale:\n",
    "        if imgsz_min == imgsz_max:\n",
    "            imgsz_min //= 1.5\n",
    "            imgsz_max //= 0.667\n",
    "        grid_min, grid_max = imgsz_min // gs, imgsz_max // gs\n",
    "        imgsz_min, imgsz_max = int(grid_min * gs), int(grid_max * gs)\n",
    "img_size = imgsz_max  # initialize with max size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data/train_local.txt\ndata/val_local.txt\n"
     ]
    }
   ],
   "source": [
    "init_seeds()\n",
    "data_dict = parse_data_cfg(data)\n",
    "train_path = data_dict['train']\n",
    "test_path = data_dict['valid']\n",
    "print(train_path)\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3\nFalse\n"
     ]
    }
   ],
   "source": [
    "print(int(data_dict['classes']))\n",
    "print(single_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "nc = 1 if single_cls else int(data_dict['classes'])  # number of classes\n",
    "hyp['cls'] *= nc / 80\n",
    "print(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous results\n",
    "for f in glob.glob('*_batch*.jpg') + glob.glob(results_file):\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cfg/yolov3-tiny-3cls.cfg\n"
     ]
    }
   ],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Summary: 37 layers, 8.6745e+06 parameters, 8.6745e+06 gradients\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = Darknet(cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "pg0, pg1, pg2 = [], [], []  # optimizer parameter groups\n",
    "for k, v in dict(model.named_parameters()).items():\n",
    "    if '.bias' in k:\n",
    "        pg2 += [v]  # biases\n",
    "    elif 'Conv2d.weight' in k:\n",
    "        pg1 += [v]  # apply weight_decay\n",
    "    else:\n",
    "        pg0 += [v]  # all else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       device='cuda:0', requires_grad=True), Parameter containing:\ntensor([ 1.38910e-02,  7.43582e-03,  2.80491e-02, -9.56991e-03, -4.50293e+00, -1.16900e+00, -1.21391e+00, -1.23476e+00,  8.56011e-03,  3.32031e-02,  2.04062e-02,  3.67516e-03, -4.52799e+00, -1.23441e+00, -1.22660e+00, -1.21941e+00,  4.10424e-02, -3.71889e-02, -3.79907e-02,  3.32781e-03, -4.46921e+00, -1.19514e+00,\n        -1.24240e+00, -1.23263e+00], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:\ntensor([-9.63692e-03,  4.63675e-02,  2.67509e-02,  3.54687e-02, -4.53759e+00, -1.15058e+00, -1.20986e+00, -1.18319e+00,  3.84825e-02, -1.95564e-03, -6.19167e-02,  1.45990e-02, -4.53755e+00, -1.19862e+00, -1.22860e+00, -1.16096e+00, -5.32212e-02, -6.17828e-02,  6.00369e-02,  5.09122e-02, -4.46140e+00, -1.23156e+00,\n        -1.20590e+00, -1.17639e+00], device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(pg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimizer groups: 13 .bias, 13 Conv2d.weight, 11 other\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(pg0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)\n",
    "optimizer.add_param_group({'params': pg1, 'weight_decay': hyp['weight_decay']})  # add pg1 with weight_decay\n",
    "optimizer.add_param_group({'params': pg2})  # add pg2 (biases)\n",
    "print('Optimizer groups: %g .bias, %g Conv2d.weight, %g other' % (len(pg2), len(pg1), len(pg0)))\n",
    "del pg0, pg1, pg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "best_fitness = 0.0\n",
    "attempt_download(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False True\n"
     ]
    }
   ],
   "source": [
    "print(weights.endswith('.pt'),len(weights)>0)\n",
    "load_darknet_weights(model, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(mixed_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheduler https://arxiv.org/pdf/1812.01187.pdf\n",
    "lf = lambda x: (((1 + math.cos(x * math.pi / epochs)) / 2) ** 1.0) * 0.95 + 0.05  # cosine\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "scheduler.last_epoch = start_epoch - 1  # see link below\n",
    "# https://discuss.pytorch.org/t/a-problem-occured-when-resuming-an-optimizer/28822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "print(scheduler.last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda 1 False True\n"
     ]
    }
   ],
   "source": [
    "print(device.type,torch.cuda.device_count(),torch.cuda.device_count() > 1,torch.distributed.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'giou': 3.54, 'cls': 1.4024999999999999, 'cls_pw': 1.0, 'obj': 64.3, 'obj_pw': 1.0, 'iou_t': 0.2, 'lr0': 0.01, 'lrf': 0.0005, 'momentum': 0.937, 'weight_decay': 0.000484, 'fl_gamma': 0.0, 'hsv_h': 0.0138, 'hsv_s': 0.678, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.0, 'shear': 0.0} False False False\n"
     ]
    }
   ],
   "source": [
    "print(hyp,rect,cache_images,single_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Caching labels (6265 found, 0 missing, 0 empty, 1 duplicate, for 6265 images): 100%|██████████| 6265/6265 [00:02<00:00, 2955.15it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = LoadImagesAndLabels(train_path, img_size, batch_size,\n",
    "                                  augment=True,\n",
    "                                  hyp=hyp,  # augmentation hyperparameters\n",
    "                                  rect=rect,  # rectangular training\n",
    "                                  cache_images=cache_images,\n",
    "                                  single_cls=single_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<utils.datasets.LoadImagesAndLabels object at 0x00000237AF335940>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "batch_size = min(batch_size, len(dataset))\n",
    "nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             num_workers=nw,\n",
    "                                             shuffle=not rect,  # Shuffle=True unless rectangular training is used\n",
    "                                             pin_memory=True,\n",
    "                                             collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Caching labels (2117 found, 0 missing, 0 empty, 0 duplicate, for 2117 images): 100%|██████████| 2117/2117 [00:00<00:00, 2666.24it/s]\n"
     ]
    }
   ],
   "source": [
    "testloader = torch.utils.data.DataLoader(LoadImagesAndLabels(test_path, imgsz_test, batch_size,\n",
    "                                                                 hyp=hyp,\n",
    "                                                                 rect=True,\n",
    "                                                                 cache_images=cache_images,\n",
    "                                                                 single_cls=single_cls),\n",
    "                                             batch_size=batch_size,\n",
    "                                             num_workers=nw,\n",
    "                                             pin_memory=True,\n",
    "                                             collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Image sizes 320 - 640 train, 640 test\nUsing 6 dataloader workers\nStarting training for 5 epochs...\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "model.nc = nc  # attach number of classes to model\n",
    "model.hyp = hyp  # attach hyperparameters to model\n",
    "model.gr = 1.0  # giou loss ratio (obj_loss = 1.0 or giou)\n",
    "model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device)  # attach class weights\n",
    "\n",
    "# Model EMA\n",
    "ema = torch_utils.ModelEMA(model)\n",
    "\n",
    "# Start training\n",
    "nb = len(dataloader)  # number of batches\n",
    "n_burn = max(3 * nb, 500)  # burn-in iterations, max(3 epochs, 500 iterations)\n",
    "maps = np.zeros(nc)  # mAP per class\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "results = (0, 0, 0, 0, 0, 0, 0)  # 'P', 'R', 'mAP', 'F1', 'val GIoU', 'val Objectness', 'val Classification'\n",
    "t0 = time.time()\n",
    "print('Image sizes %g - %g train, %g test' % (imgsz_min, imgsz_max, imgsz_test))\n",
    "print('Using %g dataloader workers' % nw)\n",
    "print('Starting training for %g epochs...' % epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(dataset.image_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Darknet(\n",
       "  (module_list): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (Conv2d): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(16, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Sequential(\n",
       "      (Conv2d): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (Conv2d): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(64, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Sequential(\n",
       "      (Conv2d): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Sequential(\n",
       "      (Conv2d): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Sequential(\n",
       "      (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (11): Sequential(\n",
       "      (ZeroPad2d): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      (MaxPool2d): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (12): Sequential(\n",
       "      (Conv2d): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(1024, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (Conv2d): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (14): Sequential(\n",
       "      (Conv2d): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(512, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (15): Sequential(\n",
       "      (Conv2d): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (16): YOLOLayer()\n",
       "    (17): FeatureConcat()\n",
       "    (18): Sequential(\n",
       "      (Conv2d): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(128, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (19): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (20): FeatureConcat()\n",
       "    (21): Sequential(\n",
       "      (Conv2d): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(256, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (22): Sequential(\n",
       "      (Conv2d): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (23): YOLOLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "  0%|          | 0/1045 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "mloss = torch.zeros(4).to(device)  # mean losses\n",
    "print(('\\n' + '%10s' * 8) % ('Epoch', 'gpu_mem', 'GIoU', 'obj', 'cls', 'total', 'targets', 'img_size'))\n",
    "pbar = tqdm(enumerate(dataloader), total=nb)  # progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False 0 5\n"
     ]
    }
   ],
   "source": [
    "print(mixed_precision,start_epoch,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "       2/4      1.2G       3.1     0.779      0.53      4.41         3       640: 100%|██████████| 1045/1045 [06:38<00:00,  2.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# batch -------------------------------------------------------------\n",
    "for i, (imgs, targets, paths, _) in pbar:  \n",
    "    ni = i + nb * epoch  # number integrated batches (since train start)\n",
    "    imgs = imgs.to(device).float() / 255.0  # uint8 to float32, 0 - 255 to 0.0 - 1.0\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # Burn-in\n",
    "    if ni <= n_burn * 2:\n",
    "        model.gr = np.interp(ni, [0, n_burn * 2], [0.0, 1.0])  # giou loss ratio (obj_loss = 1.0 or giou)\n",
    "        if ni == n_burn:  # burnin complete\n",
    "            print_model_biases(model)\n",
    "\n",
    "        for j, x in enumerate(optimizer.param_groups):\n",
    "            # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n",
    "            x['lr'] = np.interp(ni, [0, n_burn], [0.1 if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n",
    "            if 'momentum' in x:\n",
    "                x['momentum'] = np.interp(ni, [0, n_burn], [0.9, hyp['momentum']])\n",
    "\n",
    "    # Multi-Scale\n",
    "    if multi_scale:\n",
    "        if ni / accumulate % 1 == 0:  #  adjust img_size (67% - 150%) every 1 batch\n",
    "            img_size = random.randrange(grid_min, grid_max + 1) * gs\n",
    "        sf = img_size / max(imgs.shape[2:])  # scale factor\n",
    "        if sf != 1:\n",
    "            ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to 32-multiple)\n",
    "            imgs = F.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)\n",
    "\n",
    "    # Forward\n",
    "    pred = model(imgs)\n",
    "\n",
    "    # Loss\n",
    "    loss, loss_items = compute_loss(pred, targets, model)\n",
    "    #if not torch.isfinite(loss):\n",
    "    #    print('WARNING: non-finite loss, ending training ', loss_items)\n",
    "    #    return results\n",
    "\n",
    "    # Backward\n",
    "    loss *= batch_size / 64  # scale loss\n",
    "    loss.backward()\n",
    "\n",
    "    # Optimize\n",
    "    if ni % accumulate == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        ema.update(model)\n",
    "\n",
    "    # Print\n",
    "    mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n",
    "    #mem = '%.3gG' % (torch.cuda.memory_cached() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n",
    "    mem = '%.3gG' % (torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n",
    "    s = ('%10s' * 2 + '%10.3g' * 6) % ('%g/%g' % (epoch, epochs - 1), mem, *mloss, len(targets), img_size)\n",
    "    pbar.set_description(s)\n",
    "\n",
    "    # Plot\n",
    "    if ni < 1:\n",
    "        f = 'train_batch%g.jpg' % i  # filename\n",
    "        res = plot_images(images=imgs, targets=targets, paths=paths, fname=f)\n",
    "        if tb_writer:\n",
    "            tb_writer.add_image(f, res, dataformats='HWC', global_step=epoch)\n",
    "            # tb_writer.add_graph(model, imgs)  # add model to tensorboard\n",
    "# end batch ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update scheduler\n",
    "scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(notest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Process epoch results\n",
    "ema.update_attr(model)\n",
    "final_epoch = epoch + 1 == epochs\n",
    "print(final_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|██████████| 353/353 [01:04<00:00,  5.51it/s]\n",
      "                 all  2.12e+03  8.28e+03     0.346     0.543     0.401     0.417\n"
     ]
    }
   ],
   "source": [
    "if not notest or final_epoch:  # Calculate mAP\n",
    "            is_coco = any([x in data for x in ['coco.data', 'coco2014.data', 'coco2017.data']]) and model.nc == 80\n",
    "            results, maps = test.test(cfg,\n",
    "                                      data,\n",
    "                                      batch_size=batch_size,\n",
    "                                      img_size=imgsz_test,\n",
    "                                      model=ema.ema,\n",
    "                                      save_json=final_epoch and is_coco,\n",
    "                                      single_cls=single_cls,\n",
    "                                      dataloader=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write\n",
    "with open(results_file, 'a') as f:\n",
    "    f.write(s + '%10.3g' * 7 % results + '\\n')  # P, R, mAP, F1, test_losses=(GIoU, obj, cls)\n",
    "if len(name) and bucket:\n",
    "    os.system('gsutil cp results.txt gs://%s/results/results%s.txt' % (bucket, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = fitness(np.array(results).reshape(1, -1))  # fitness_i = weighted combination of [P, R, mAP, F1]\n",
    "if fi > best_fitness:\n",
    "    best_fitness = fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[    0.40265]\nthe best_fitness is 0.402650 .\n\n"
     ]
    }
   ],
   "source": [
    "print(best_fitness)\n",
    "print('the best_fitness is %f .\\n' % (best_fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "save = (not opt.nosave) or (final_epoch and not opt.evolve)\n",
    "if save:\n",
    "    with open(results_file, 'r') as f:  # create checkpoint\n",
    "        chkpt = {'epoch': epoch,\n",
    "                         'best_fitness': best_fitness,\n",
    "                         'training_results': f.read(),\n",
    "                         'model': ema.ema.module.state_dict() if hasattr(model, 'module') else ema.ema.state_dict(),\n",
    "                         'optimizer': None if final_epoch else optimizer.state_dict()}\n",
    "\n",
    "            # Save last, best and delete\n",
    "        torch.save(chkpt, last)\n",
    "        if (best_fitness == fi) and not final_epoch:\n",
    "            torch.save(chkpt, best)\n",
    "        del chkpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}