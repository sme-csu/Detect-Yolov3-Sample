{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation.All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Detection Task with Azure Machine Learning\n",
    "In this tutorial,you will use Azure Machine Learning Studio to train and deploy model for image detection task with pytorch tiny yolo v3 neutral network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial depends on having the Azure Machine Learning SDK version 1.14.0 onwards installed. You can check the AML core SDK version using the code cell below.\n",
    "\n",
    "- If you are using a compute instance in Azure Machine Learning to run this notebook series, you are all set.If you don't already have an Azure Machine Learning compute cluster, please follow the [Create and manage an Azure Machine Learning compute instance](https://docs.microsoft.com/azure/machine-learning/how-to-create-manage-compute-instance?tabs=python) and the [Configure a development environment for Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/how-to-configure-environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "Opt-in diagnostics for better experience, quality, and security of future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612288551376
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Connect to workspace\n",
    "\n",
    "Create a workspace object from the existing workspace. `Workspace.from_config()` reads the file **config.json** and loads the details into an object named `ws`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612288557005
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Prepare Tarining Data\n",
    "Before training a model, you need to understand the data that you are using to train it.\n",
    "\n",
    "To register an Azure blob container as a datastore, use register_azure_blob_container().\n",
    "The following code creates and registers the blob_datastore_name datastore to the ws workspace. This datastore accesses the my-container-name blob container on the my-account-name storage account, by using the provided account access key. Review the storage access & permissions section for guidance on virtual network scenarios, and where to find required authentication credentials.\n",
    "\n",
    "For more information, please visit [Connect to storage services on Azure](https://docs.microsoft.com/azure/machine-learning/how-to-access-data#azure-blob-container)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612285596540
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.core import Dataset\n",
    "datastore = Datastore.register_azure_blob_container(workspace = ws, \n",
    "                                        datastore_name = 'img_ds',\n",
    "                                        container_name = 'source-data',\n",
    "                                        account_name = 'amlpocwestus6466069240',\n",
    "                                        sas_token = '?sv=2019-12-12&ss=b&srt=co&sp=rlx&se=2021-03-31T15:28:38Z&st=2021-02-02T07:28:38Z&spr=https&sig=3KyJdypHKf%2FxktopuYLAbzy6YszG3LTpMUKHD5Qkn3I%3D',\n",
    "                                        overwrite=False\n",
    "                                        )\n",
    "datastore_paths = [(datastore, 'anji_data')]\n",
    "dataset = Dataset.File.from_files(path=datastore_paths)\n",
    "print(datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Create an experiment\n",
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) named as exp-yolov3-sample for this training, deployment and inference process.\n",
    "Prepare dependencies for yolo v3 pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612285596826
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Environment\n",
    "experiment_name = 'exp-yolov3-sample'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an environment\n",
    "\n",
    "Prepare dependencies for yolo v3 pytorch implementation.\n",
    "\n",
    "There are also several Azure ML's curated environments are available in your workspace by default. For more information, please visit [Curated environments](https://docs.microsoft.com/azure/machine-learning/how-to-use-environments#use-a-curated-environment) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_env = Environment.from_conda_specification(name = 'pytorch-1.6-gpu', \n",
    "                                                file_path = './conda_dependencies.yml'\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Prepare Script parameters\n",
    "Create a ScriptRunConfig object to specify the configuration details of your training job, including your training script, environment to use and the parameters for training.\n",
    "\n",
    "The parameters for training can be assigned here as arguments, such as -- epoches, --batchsizes,  --cfg and so on. The detailed parameters can be found in train.py file. \n",
    "\n",
    "Dataset must be mounted here. The path and name of dataset can be assigned differently.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612285596916
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "project_folder = '.'\n",
    "src = ScriptRunConfig(source_directory=project_folder,\n",
    "                      script='train.py',\n",
    "                      arguments=['--epochs', 6,'--data-folder', dataset.as_mount('/tmp/tmp_imgdata')],\n",
    "                      environment=pytorch_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Submit job\n",
    "Run your experiment by submitting your ScriptRunConfig object.The labels and images of training data will be imported. The loss and other evaluation criteria will be calculated since the training processes after each epoch. \n",
    "\n",
    "The best model will be saved in outputs folder. Print intermediate results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612285606154
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "run = experiment.submit(src,tags={\"purpose\":\"AML yolov3 sample\"})\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get log results upon completion\n",
    "\n",
    "Model training happens in the background. You can use `wait_for_completion` to block and wait until the model has completed training before running more code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612258749705
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Comfirm the training experiment is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(run.get_status() == \"Completed\")\n",
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Register the best Model\n",
    "\n",
    "The next step in the script wrote the file `outputs/best.pt` in a directory named `outputs` in the VM of the cluster where the job is executed. `outputs` is a special directory in that all content in this  directory is automatically uploaded to your workspace.  This content appears in the run record in the experiment under your workspace. Hence, the model file is now also available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612287170018
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = run.register_model(model_name = 'yolov3-sample-model',\n",
    "                            model_path = 'outputs/best.pt')\n",
    "\n",
    "# model = Model.register(workspace = ws,\n",
    "#                         model_path =\"weights/best_219.pt\",\n",
    "#                         model_name = \"yolov3-sample-model\",\n",
    "#                         tags = {\"yolov3\": \"demo\"},\n",
    "#                         description = \"yolov3 sample\",)\n",
    "\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Deploy as web service\n",
    "\n",
    "Deploy the model as a web service hosted in ACI. \n",
    "\n",
    "To build the correct environment for ACI, provide the following:\n",
    "* A scoring script to show how to use the model\n",
    "* A configuration file to build the ACI\n",
    "* The model you trained before\n",
    "\n",
    "### Import packages\n",
    "\n",
    "Import the Python packages needed for model deployment.\n",
    "\n",
    "### Set up the environment\n",
    "\n",
    "Start by setting up a testing environment.\n",
    "\n",
    "\n",
    "### Prepare scoring script\n",
    "\n",
    "Prepare the scoring script, called score.py, used by the web service call to show how to use the model.\n",
    "\n",
    "You must include two required functions into the scoring script:\n",
    "* The `init()` function, which typically loads the model into a global object. This function is run only once when the Docker container is started. \n",
    "\n",
    "* The `run(input_data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "pytorch_env = Environment.from_conda_specification(name = 'pytorch-1.6-gpu', file_path = './conda_dependencies.yml')\n",
    "dockerfile = \"\"\"\n",
    "FROM mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04\n",
    "RUN apt update\n",
    "RUN apt-get -y install sudo\n",
    "RUN sudo apt -y install libgl1-mesa-glx\n",
    "\"\"\"\n",
    "pytorch_env.docker.enabled = True\n",
    "pytorch_env.docker.base_image = None\n",
    "pytorch_env.docker.base_dockerfile = dockerfile\n",
    "pytorch_env.inferencing_stack_version = 'latest'\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "        entry_script=\"score.py\", \n",
    "        environment=pytorch_env,\n",
    "        source_directory = \"./\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create configuration file\n",
    "\n",
    "Create a deployment configuration file and specify the number of CPUs and gigabyte of RAM needed for your ACI container. While it depends on your model, the default of 1 core and 1 gigabyte of RAM is usually sufficient for many models. If you feel you need more later, you would have to recreate the image and redeploy the service.\n",
    "\n",
    "### Deploy in ACI\n",
    "Estimated time to complete: **about 5-10 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612290235420
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=2, \n",
    "                                               memory_gb=2, \n",
    "                                               tags={'framework':'pytorch'},\n",
    "                                               description='ACI with Yolov3')\n",
    "model = Model(ws, 'yolov3-sample-model')\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                           name='aci-yolov3-sample', \n",
    "                           models=[model], \n",
    "                           inference_config=inference_config, \n",
    "                           deployment_config=aciconfig)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612290240813
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "service.get_logs()\n",
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Test the model\n",
    "\n",
    "Use the deployed model to do inference process: input an image and use the deployed model to detect objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612290246906
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(Image.open('testfiles/test-image-1.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the web service\n",
    "We test the web sevice by passing the test images content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612290250685
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from base64 import b64encode\n",
    "# send a random row from the test set to score\n",
    "with open('testfiles/test-image-1.jpg', 'rb') as jpg_file:\n",
    "    byte_content = jpg_file.read()\n",
    "    jpg_file.close()\n",
    "base64_bytes = b64encode(byte_content)\n",
    "base64_string = base64_bytes.decode()\n",
    "\n",
    "input_data=json.dumps({'data': base64_string})\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "max_len = len(resp.text) -1\n",
    "result = resp.text[1:max_len].replace(\"\\\\\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612290254014
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "result_image = json.loads(result)[\"result_image\"]\n",
    "\n",
    "image_data = base64.b64decode(result_image)\n",
    "\n",
    "with open('testfiles/test-impage-1-detection.jpg', 'wb') as jpg_file:\n",
    "    jpg_file.write(image_data)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(Image.open('testfiles/test-impage-1-detection.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Clean up resources(Optional) \n",
    "\n",
    "Delete ACI and datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "service.delete()\n",
    "datastore.unregister()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
